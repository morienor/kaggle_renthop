{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py35/lib/python3.5/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_json(\"./input/train.json\")\n",
    "test_df = pd.read_json(\"./input/test.json\")\n",
    "train_df.reset_index(inplace = True)\n",
    "test_df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This section generates price features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a log transformed version of price\n",
    "train_df['price_log'] = np.log(train_df['price'])\n",
    "\n",
    "# create a version of log price variable with very high and very low values clipped\n",
    "high_limit = np.percentile(train_df.price_log.values, 99) #get 99th percentile\n",
    "low_limit = np.percentile(train_df.price_log.values, 1) #get 1th percentile\n",
    "train_df['price_log_cut'] = train_df['price_log']\n",
    "train_df['price_log_cut'].ix[train_df['price_log']>high_limit] = high_limit\n",
    "train_df['price_log_cut'].ix[train_df['price_log']<low_limit] = low_limit\n",
    "\n",
    "#also create a version with normal values - but clip them.\n",
    "high_limit = np.percentile(train_df.price.values, 99) #get 99th percentile\n",
    "low_limit = np.percentile(train_df.price.values, 1) #get 1th percentile\n",
    "train_df['price_cut'] = train_df['price']\n",
    "train_df['price_cut'].ix[train_df['price']>high_limit] = high_limit\n",
    "train_df['price_cut'].ix[train_df['price']<low_limit] = low_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a version of variable that has offset value relative to median\n",
    "train_df['price_cut_offset'] = train_df['price_cut'] - np.median(train_df['price_cut'])\n",
    "train_df['price_log_cut_offset'] = train_df['price_log_cut'] - np.median(train_df['price_log_cut'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = [\"price_cut_offset\",\"price_log_cut_offset\"]\n",
    "with open(\"./features/simple_price_features\", \"wb\") as f:\n",
    "    pickle.dump(train_df[features], f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This section looks at the text description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment the feature is only build on test data set - it should be build on the total corpus\n",
    "There are further things to do here - just conceptual implimentation\n",
    "\n",
    "It might be actually useful to see the number of punctuatios (like!!! or ! ) in the text description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from utils import getTFV, getBOW, dump_feat_name\n",
    "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pickle\n",
    "from copy import copy\n",
    "from gensim.matutils import corpus2csc\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models import Phrases\n",
    "from nltk import bigrams as bgm\n",
    "import codecs\n",
    "import os.path\n",
    "import glob\n",
    "import os\n",
    "import ast\n",
    "import re\n",
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()  \n",
    "from nltk.corpus import stopwords # Import the stop word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def description_to_words( raw_description ):\n",
    "    # Function to convert a raw description to string of words\n",
    "    # The input is a single string (a raw description), and \n",
    "    # the output is a single string (a preprocessed description)\n",
    "    #\n",
    "    \n",
    "    # 1. give tags and markup an extra space - otherwise gets squashed together later on\n",
    "    \n",
    "    raw_description_1 = re.sub(\"<\",           # The pattern to search for\n",
    "                          \"  <\",                   # The pattern to replace it with\n",
    "                          str(raw_description) )  # The text to search\n",
    "\n",
    "    raw_description_2 = re.sub(\">\",           # The pattern to search for\n",
    "                          \"> \",                   # The pattern to replace it with\n",
    "                          str(raw_description_1) ) \n",
    "    \n",
    "    \n",
    "    # 2. Remove HTML\n",
    "    review_desc = BeautifulSoup(raw_description_2,\"html.parser\").get_text() \n",
    "    #\n",
    "\n",
    "    # 3. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_desc) \n",
    "    #\n",
    "    \n",
    "    # 4. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()  \n",
    "    \n",
    "    # 5. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 6. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 7. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Top West Village location, beautiful Pre-war building with laundry in the basement and live in super!<br/><br/>Apartment features a large bedroom with closet. Separate living room, kitchen features granite tops, dishwasher and microwave included, marble bathroom and hardwood flooring. Building is very well maintained and conveniently located near A,C,E,L,1,2,3 trains. Surrounded by many local cafe?s, restaurants, available for November 1st move in!<br/><br/>To view this apartment or any other please contact me via email or call at the number listed.<br/><br/><br/><br/><br/><br/>Bond New York is a real estate broker that supports equal housing opportunity.<p><a  website_redacted \n",
      "\n",
      "top top west village location beautiful pre war building laundry basement live super apartment features large bedroom closet separate living room kitchen features granite tops dishwasher microwave included marble bathroom hardwood flooring building well maintained conveniently located near c e l trains surrounded many local cafe restaurants available november st move view apartment please contact via email call number listed bond new york real estate broker supports equal housing opportunity\n"
     ]
    }
   ],
   "source": [
    "#look at how the text description changed before and after cleansing\n",
    "test_11 = description_to_words(train_df[\"description\"][2])\n",
    "print (train_df[\"description\"][2])\n",
    "print()\n",
    "print (test_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set movie reviews...\n",
      "\n",
      "Review 5000 of 49352\n",
      "\n",
      "Review 10000 of 49352\n",
      "\n",
      "Review 15000 of 49352\n",
      "\n",
      "Review 20000 of 49352\n",
      "\n",
      "Review 25000 of 49352\n",
      "\n",
      "Review 30000 of 49352\n",
      "\n",
      "Review 35000 of 49352\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py35/lib/python3.5/site-packages/bs4/__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 40000 of 49352\n",
      "\n",
      "Review 45000 of 49352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Cleaning and parsing the training set movie reviews...\\n\")\n",
    "num_descriptions = train_df[\"description\"].size\n",
    "\n",
    "clean_train_description = []\n",
    "for i in range(0, num_descriptions):\n",
    "    # If the index is evenly divisible by 5000, print a message\n",
    "    if( (i+1)%5000 == 0 ):\n",
    "        print( \"Description %d of %d\\n\" % ( i+1, num_descriptions ) )                                                                   \n",
    "    clean_train_description.append( description_to_words( train_df[\"description\"][i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 50)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 50) \n",
    "\n",
    "train_data_features = vectorizer.fit_transform(clean_train_description)\n",
    "train_data_features = train_data_features.toarray()\n",
    "train_text_bow_features = pd.DataFrame(train_data_features)\n",
    "print (train_text_bow_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dscrp_ft_apartment', 'dscrp_ft_appliances', 'dscrp_ft_area', 'dscrp_ft_bathroom', 'dscrp_ft_beautiful', 'dscrp_ft_bedroom', 'dscrp_ft_building', 'dscrp_ft_call', 'dscrp_ft_ceilings', 'dscrp_ft_city', 'dscrp_ft_closet', 'dscrp_ft_com', 'dscrp_ft_contact', 'dscrp_ft_dishwasher', 'dscrp_ft_doorman', 'dscrp_ft_east', 'dscrp_ft_email', 'dscrp_ft_features', 'dscrp_ft_fee', 'dscrp_ft_floor', 'dscrp_ft_floors', 'dscrp_ft_full', 'dscrp_ft_granite', 'dscrp_ft_great', 'dscrp_ft_hardwood', 'dscrp_ft_high', 'dscrp_ft_kagglemanager', 'dscrp_ft_kitchen', 'dscrp_ft_large', 'dscrp_ft_laundry', 'dscrp_ft_living', 'dscrp_ft_located', 'dscrp_ft_location', 'dscrp_ft_marble', 'dscrp_ft_new', 'dscrp_ft_one', 'dscrp_ft_park', 'dscrp_ft_private', 'dscrp_ft_renovated', 'dscrp_ft_renthop', 'dscrp_ft_restaurants', 'dscrp_ft_room', 'dscrp_ft_space', 'dscrp_ft_spacious', 'dscrp_ft_stainless', 'dscrp_ft_steel', 'dscrp_ft_text', 'dscrp_ft_unit', 'dscrp_ft_windows', 'dscrp_ft_york']\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "vocab = [\"dscrp_ft_\" + s for s in vocab]\n",
    "print (vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_text_bow_features.colums = vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"./master/features/AH/bow\", \"wb\") as f:\n",
    "    pickle.dump(train_text_bow_features, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## date features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let us extract some features like year, month, day, hour from date columns #\n",
    "train_df['created'] = pd.to_datetime(train_df['created'])\n",
    "test_df['created'] = pd.to_datetime(test_df['created'])\n",
    "\n",
    "train_df[\"created_year\"] = train_df[\"created\"].dt.year\n",
    "test_df[\"created_year\"] = test_df[\"created\"].dt.year\n",
    "train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
    "test_df[\"created_month\"] = test_df[\"created\"].dt.month\n",
    "train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
    "test_df[\"created_day\"] = test_df[\"created\"].dt.day\n",
    "train_df[\"created_hour\"] = train_df[\"created\"].dt.hour\n",
    "test_df[\"created_hour\"] = test_df[\"created\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_features = [\"created_year\",\"created_month\",\"created_day\",\"created_hour\"]\n",
    "# write train features\n",
    "with open(\"./master/features/AH/train_date_feat\", \"wb\") as f:\n",
    "    pickle.dump(train_df[date_features], f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(\"./master/features/AH/test_day_feat\", \"wb\") as f:\n",
    "    pickle.dump(test_df[date_features], f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical features\n",
    "\n",
    "this is the same as here - seems to be used by everyone in some way or another!\n",
    "https://www.kaggle.com/sudalairajkumar/two-sigma-connect-rental-listing-inquiries/xgb-starter-in-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 4 categorical features in our data\n",
    "\n",
    "-display_address\n",
    "\n",
    "-manager_id\n",
    "\n",
    "-building_id\n",
    "\n",
    "-listing_id\n",
    "\n",
    "So let us label encode these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\n",
    "\n",
    "for f in categorical:\n",
    "        if train_df[f].dtype=='object':\n",
    "            #print(f)\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n",
    "            train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "            test_df[f] = lbl.transform(list(test_df[f].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have features column which is a list of string values. So we can first combine all the strings together to get a single string and then apply count vectorizer on top of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                     \n",
      "1    Doorman Elevator Fitness_Center Cats_Allowed D...\n",
      "2    Laundry_In_Building Dishwasher Hardwood_Floors...\n",
      "3                               Hardwood_Floors No_Fee\n",
      "4                                              Pre-War\n",
      "Name: features, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_df['features'] = train_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "test_df['features'] = test_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "print(train_df[\"features\"].head())\n",
    "tfidf = CountVectorizer(stop_words='english', max_features=200)\n",
    "vocab_2 = tfidf.get_feature_names()\n",
    "tr_sparse = tfidf.fit_transform(train_df[\"features\"])\n",
    "te_sparse = tfidf.transform(test_df[\"features\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us stack both the dense and sparse features into a single dataset and also get the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 204) (74659, 204)\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "train_df_cat_feat = sparse.hstack([train_df[categorical], tr_sparse]).tocsr()\n",
    "test_df_cat_feat = sparse.hstack([test_df[categorical], te_sparse]).tocsr()\n",
    "\n",
    "print(train_df_cat_feat.shape, test_df_cat_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this creates pandas DataFrame out of the scipy sparse matrix\n",
    "# probably not the most efficient way of doing things\n",
    "train_df_cat_feat_pd = pd.DataFrame(train_df_cat_feat.toarray())\n",
    "test_df_cat_feat_pd = pd.DataFrame(test_df_cat_feat.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lost column names along the way - need to add them back\n",
    "train_df_cat_feat_pd.columns = categorical + vocab_2\n",
    "test_df_cat_feat_pd.columns = categorical + vocab_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features - manager:\n",
    "\n",
    "from here: \n",
    "\n",
    "https://www.kaggle.com/den3b81/two-sigma-connect-rental-listing-inquiries/improve-perfomances-using-manager-features\n",
    "\n",
    "\n",
    "This features involvs using target variable in its creation\n",
    "In the original kernel it ends up being created for each CV - this is the only way to build it as otherwise it will overfit in any cross validation. The actual feature to be used on the test df should be calculated on the train df and them assigned to the same managers.\n",
    "\n",
    "Probably requires more careful thinking on how to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's split the data\n",
    "X = df[features_to_use]\n",
    "y = df[\"interest_level\"]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            high_frac  low_frac  medium_frac  count\n",
      "manager_id                                         \n",
      "4386         0.000000  0.333333     0.666667      3\n",
      "4387         0.625000  0.125000     0.250000      8\n",
      "4388         0.000000  0.000000     1.000000      1\n",
      "4389         0.000000  0.000000     1.000000      1\n",
      "4390         0.142857  0.142857     0.714286      7\n",
      "4391         0.000000  0.000000     1.000000      1\n",
      "4392         0.000000  0.000000     1.000000      7\n",
      "4394         0.000000  0.000000     1.000000      2\n",
      "4396         0.142857  0.142857     0.714286      7\n",
      "4397         0.034783  0.295652     0.669565    115\n"
     ]
    }
   ],
   "source": [
    "# compute fractions and count for each manager\n",
    "target_num_map={\"high\":0, \"medium\":1, \"low\":2}\n",
    "train_df[\"interest_level_num\"]= train_df[\"interest_level\"].apply(lambda x: target_num_map[x]).values\n",
    "\n",
    "temp = pd.concat([train_df.manager_id, pd.get_dummies(train_df['interest_level_num'])], axis = 1).groupby('manager_id').mean()\n",
    "\n",
    "temp.columns = ['high_frac','low_frac', 'medium_frac']\n",
    "temp['count'] = train_df.groupby('manager_id').count().iloc[:,1]\n",
    "\n",
    "# remember the manager_ids look different because we encoded them in the previous step \n",
    "print(temp.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high_frac        0.081314\n",
      "low_frac         0.245492\n",
      "medium_frac      0.673194\n",
      "manager_skill    0.835822\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# compute skill\n",
    "temp['manager_skill'] = temp['high_frac']*2 + temp['medium_frac']\n",
    "\n",
    "# get ixes for unranked managers...\n",
    "unranked_managers_ixes = temp['count']<20\n",
    "# ... and ranked ones\n",
    "ranked_managers_ixes = ~unranked_managers_ixes\n",
    "\n",
    "# compute mean values from ranked managers and assign them to unranked ones\n",
    "mean_values = temp.loc[ranked_managers_ixes, ['high_frac','low_frac', 'medium_frac','manager_skill']].mean()\n",
    "print(mean_values)\n",
    "temp.loc[unranked_managers_ixes,['high_frac','low_frac', 'medium_frac','manager_skill']] = mean_values.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_address</th>\n",
       "      <th>manager_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>street_address</th>\n",
       "      <th>24</th>\n",
       "      <th>_balconies</th>\n",
       "      <th>_dishwasher_</th>\n",
       "      <th>_dryer</th>\n",
       "      <th>_eat</th>\n",
       "      <th>_elev</th>\n",
       "      <th>...</th>\n",
       "      <th>washer_in_unit</th>\n",
       "      <th>wheelchair_access</th>\n",
       "      <th>wheelchair_ramp</th>\n",
       "      <th>wifi_access</th>\n",
       "      <th>work</th>\n",
       "      <th>high_frac</th>\n",
       "      <th>low_frac</th>\n",
       "      <th>medium_frac</th>\n",
       "      <th>count</th>\n",
       "      <th>manager_skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12282</td>\n",
       "      <td>1568</td>\n",
       "      <td>3797</td>\n",
       "      <td>23484</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>90</td>\n",
       "      <td>0.744444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9080</td>\n",
       "      <td>1988</td>\n",
       "      <td>8986</td>\n",
       "      <td>23680</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>86</td>\n",
       "      <td>0.988372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13719</td>\n",
       "      <td>3733</td>\n",
       "      <td>8889</td>\n",
       "      <td>9827</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.365672</td>\n",
       "      <td>0.574627</td>\n",
       "      <td>134</td>\n",
       "      <td>0.694030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10866</td>\n",
       "      <td>282</td>\n",
       "      <td>1848</td>\n",
       "      <td>14237</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068063</td>\n",
       "      <td>0.125654</td>\n",
       "      <td>0.806283</td>\n",
       "      <td>191</td>\n",
       "      <td>0.942408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15072</td>\n",
       "      <td>2618</td>\n",
       "      <td>0</td>\n",
       "      <td>19227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081314</td>\n",
       "      <td>0.245492</td>\n",
       "      <td>0.673194</td>\n",
       "      <td>15</td>\n",
       "      <td>0.835822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   display_address  manager_id  building_id  street_address  24  _balconies  \\\n",
       "0            12282        1568         3797           23484   0           0   \n",
       "1             9080        1988         8986           23680   0           0   \n",
       "2            13719        3733         8889            9827   0           0   \n",
       "3            10866         282         1848           14237   0           0   \n",
       "4            15072        2618            0           19227   0           0   \n",
       "\n",
       "   _dishwasher_  _dryer  _eat  _elev      ...        washer_in_unit  \\\n",
       "0             0       0     0      0      ...                     0   \n",
       "1             0       0     0      0      ...                     0   \n",
       "2             0       0     0      0      ...                     0   \n",
       "3             0       0     0      0      ...                     0   \n",
       "4             0       0     0      0      ...                     0   \n",
       "\n",
       "   wheelchair_access  wheelchair_ramp  wifi_access  work  high_frac  low_frac  \\\n",
       "0                  0                0            0     0   0.000000  0.255556   \n",
       "1                  0                0            0     0   0.000000  0.011628   \n",
       "2                  0                0            0     0   0.059701  0.365672   \n",
       "3                  0                0            0     0   0.068063  0.125654   \n",
       "4                  0                0            0     0   0.081314  0.245492   \n",
       "\n",
       "   medium_frac  count  manager_skill  \n",
       "0     0.744444     90       0.744444  \n",
       "1     0.988372     86       0.988372  \n",
       "2     0.574627    134       0.694030  \n",
       "3     0.806283    191       0.942408  \n",
       "4     0.673194     15       0.835822  \n",
       "\n",
       "[5 rows x 209 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inner join to assign manager features to the managers in the training dataframe\n",
    "train_df_cat_feat_pd = train_df_cat_feat_pd.merge(temp.reset_index(),how='left', left_on='manager_id', right_on='manager_id')\n",
    "train_df_cat_feat_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_address</th>\n",
       "      <th>manager_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>street_address</th>\n",
       "      <th>24</th>\n",
       "      <th>_balconies</th>\n",
       "      <th>_dishwasher_</th>\n",
       "      <th>_dryer</th>\n",
       "      <th>_eat</th>\n",
       "      <th>_elev</th>\n",
       "      <th>...</th>\n",
       "      <th>washer_in_unit</th>\n",
       "      <th>wheelchair_access</th>\n",
       "      <th>wheelchair_ramp</th>\n",
       "      <th>wifi_access</th>\n",
       "      <th>work</th>\n",
       "      <th>high_frac</th>\n",
       "      <th>low_frac</th>\n",
       "      <th>medium_frac</th>\n",
       "      <th>count</th>\n",
       "      <th>manager_skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13274</td>\n",
       "      <td>3076</td>\n",
       "      <td>5535</td>\n",
       "      <td>24898</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13391</td>\n",
       "      <td>3593</td>\n",
       "      <td>0</td>\n",
       "      <td>5492</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081314</td>\n",
       "      <td>0.245492</td>\n",
       "      <td>0.673194</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.835822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>990</td>\n",
       "      <td>2677</td>\n",
       "      <td>2813</td>\n",
       "      <td>541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081314</td>\n",
       "      <td>0.245492</td>\n",
       "      <td>0.673194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.835822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>481</td>\n",
       "      <td>201</td>\n",
       "      <td>5477</td>\n",
       "      <td>10531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.360656</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.967213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12317</td>\n",
       "      <td>3157</td>\n",
       "      <td>4428</td>\n",
       "      <td>10907</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.763889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   display_address  manager_id  building_id  street_address  24  _balconies  \\\n",
       "0            13274        3076         5535           24898   0           0   \n",
       "1            13391        3593            0            5492   0           0   \n",
       "2              990        2677         2813             541   0           0   \n",
       "3              481         201         5477           10531   0           0   \n",
       "4            12317        3157         4428           10907   0           0   \n",
       "\n",
       "   _dishwasher_  _dryer  _eat  _elev      ...        washer_in_unit  \\\n",
       "0             0       0     0      0      ...                     0   \n",
       "1             0       0     0      0      ...                     0   \n",
       "2             0       0     0      0      ...                     0   \n",
       "3             0       0     0      0      ...                     0   \n",
       "4             0       0     0      0      ...                     0   \n",
       "\n",
       "   wheelchair_access  wheelchair_ramp  wifi_access  work  high_frac  low_frac  \\\n",
       "0                  0                0            0     0   0.208333  0.333333   \n",
       "1                  0                0            0     0   0.081314  0.245492   \n",
       "2                  0                0            0     0   0.081314  0.245492   \n",
       "3                  1                0            0     0   0.360656  0.393443   \n",
       "4                  0                0            0     0   0.083333  0.319444   \n",
       "\n",
       "   medium_frac  count  manager_skill  \n",
       "0     0.458333   24.0       0.875000  \n",
       "1     0.673194    9.0       0.835822  \n",
       "2     0.673194    1.0       0.835822  \n",
       "3     0.245902   61.0       0.967213  \n",
       "4     0.597222   72.0       0.763889  \n",
       "\n",
       "[5 rows x 209 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the features computed on the training dataset to the validation dataset\n",
    "test_df_cat_feat_pd = test_df_cat_feat_pd.merge(temp.reset_index(),how='left', left_on='manager_id', right_on='manager_id')\n",
    "new_manager_ixes = test_df_cat_feat_pd['high_frac'].isnull()\n",
    "test_df_cat_feat_pd.loc[new_manager_ixes,['high_frac','low_frac', 'medium_frac','manager_skill']] = mean_values.values\n",
    "test_df_cat_feat_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write train features\n",
    "with open(\"./master/features/AH/train_categ_feat\", \"wb\") as f:\n",
    "    pickle.dump(train_df_cat_feat_pd, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(\"./master/features/AH/test_categ_feat\", \"wb\") as f:\n",
    "    pickle.dump(test_df_cat_feat_pd, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TO DO:\n",
    "\n",
    "Convert building_ids and manager_ids with only 1 observation into a separate group\n",
    "\n",
    "### simple features:\n",
    "price per bed\n",
    "\n",
    "price per bath\n",
    "\n",
    "baths per bed\n",
    "\n",
    "bedrooms/(bedrooms+bathrooms)\n",
    "\n",
    "### text features\n",
    "sentiment analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
